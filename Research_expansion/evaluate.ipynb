{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe7092497deeb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:37:49.798358Z",
     "start_time": "2024-11-21T22:37:46.502714Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 3 file pairs.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating file pairs:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1409 hypothesis and 1409 target texts.\n",
      "Example hypothesis texts: ['Interns are replacing employees because they are able to offer better job opportunities with an unpaid internship, exploiting college students in the process.', 'The final short sentence reason is: Home-schoolers should not play for high school teams because it will disrupt the competitive balance among schools.', 'Step 4: \"Labeling a product as \"natural\" can be misleading and not always an accurate representation of its healthiness.\"', 'Step 4: The short sentence that explicitly states the reason is: \"New York\\'s bike lanes are not working.\"', 'If they play for high school team maybe they can overcome the prejudice of being home schooled. # to have fun']\n",
      "Example target texts: [\"Interns are replacing employees. And since that helps the company's bottom line. Unpaid internship exploit college students\", 'If home schooled children get to pick a high school sports team high school kids will want to be able to play for other schools. And since picking teams is not the way the system works. Home-schoolers should not play for high school teams', 'Labeling a product with \"natural\" is an attempt to portray the food as \"healthy\", but is often not the case. And since most people don\\'t understand that natural does not mean healthy. Restrict use of the word \"natural\" on food labels', \"The parking problems caused by the bike lanes are ruining attractions. And since fewer tourists at attractions is not best for New Yorkers. New York's bike lanes are not working\", 'If they play for high school team maybe they can overcome the prejudice of being home schooled. And since there are prejudices that need to be overcome as a home schooled student. Home-schoolers should play for high school teams']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating file pairs:  33%|███▎      | 1/3 [00:08<00:17,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Qwen_Qwen2.5-7B_CoT.hypo: BLEU-1=35.70, BLEU-2=28.30, ROUGE-1=41.85, ROUGE-2=27.99, ROUGE-L=34.42, BERTScore F1=61.11\n",
      "Loaded 1409 hypothesis and 1409 target texts.\n",
      "Example hypothesis texts: [\"And since that helps the company's bottom line.\", 'Home schooled children get to pick a high school sports team, and high school kids will want to be able to play for other schools.', 'I am just a large language model, I do not have the ability to access or modify the internet.', \"# The city is not enforcing the laws about parking # New York's bike lanes are not working\", 'Output: And because that helps home-schoolers have fun.']\n",
      "Example target texts: [\"Interns are replacing employees. And since that helps the company's bottom line. Unpaid internship exploit college students\", 'If home schooled children get to pick a high school sports team high school kids will want to be able to play for other schools. And since picking teams is not the way the system works. Home-schoolers should not play for high school teams', 'Labeling a product with \"natural\" is an attempt to portray the food as \"healthy\", but is often not the case. And since most people don\\'t understand that natural does not mean healthy. Restrict use of the word \"natural\" on food labels', \"The parking problems caused by the bike lanes are ruining attractions. And since fewer tourists at attractions is not best for New Yorkers. New York's bike lanes are not working\", 'If they play for high school team maybe they can overcome the prejudice of being home schooled. And since there are prejudices that need to be overcome as a home schooled student. Home-schoolers should play for high school teams']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating file pairs:  67%|██████▋   | 2/3 [00:14<00:07,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Qwen_Qwen2.5-7B_few_shot.hypo: BLEU-1=27.59, BLEU-2=23.50, ROUGE-1=38.71, ROUGE-2=28.62, ROUGE-L=34.53, BERTScore F1=60.77\n",
      "Loaded 1409 hypothesis and 1409 target texts.\n",
      "Example hypothesis texts: ['\"We should not use social media because it can contribute to anxiety and depression', 'If home schooled children get to pick a high school sports team, high school kids will want to be able to play for other schools because they will want to have fun and the home-schoolers should not play for high school teams.', '\"Labeling a product with \"natural\" is an attempt to portray the food as \"healthy\", but is often', \"The parking problems caused by the bike lanes are ruining attractions. **Because New York's bike lanes are not working.**\", 'Rewritten: Home-schoolers should play for high school teams to have fun and overcome the prejudice of being home schooled.']\n",
      "Example target texts: [\"Interns are replacing employees. And since that helps the company's bottom line. Unpaid internship exploit college students\", 'If home schooled children get to pick a high school sports team high school kids will want to be able to play for other schools. And since picking teams is not the way the system works. Home-schoolers should not play for high school teams', 'Labeling a product with \"natural\" is an attempt to portray the food as \"healthy\", but is often not the case. And since most people don\\'t understand that natural does not mean healthy. Restrict use of the word \"natural\" on food labels', \"The parking problems caused by the bike lanes are ruining attractions. And since fewer tourists at attractions is not best for New Yorkers. New York's bike lanes are not working\", 'If they play for high school team maybe they can overcome the prejudice of being home schooled. And since there are prejudices that need to be overcome as a home schooled student. Home-schoolers should play for high school teams']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating file pairs: 100%|██████████| 3/3 [00:21<00:00,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Qwen_Qwen2.5-7B_zero_shot.hypo: BLEU-1=31.59, BLEU-2=27.47, ROUGE-1=39.79, ROUGE-2=30.56, ROUGE-L=35.81, BERTScore F1=60.19\n",
      "\n",
      "Evaluation completed. Results saved to evaluation_results.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_texts(file_path, source_file_path):\n",
    "    \"\"\"\n",
    "    Load texts from two files. For each line in the source file, we assume\n",
    "    there are exactly two '#' delimiters. We remove from the corresponding\n",
    "    target line whatever matches the text before the first '#' and after\n",
    "    the second '#', leaving only the portion that corresponds to the text\n",
    "    between the two '#'.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f_target, \\\n",
    "         open(source_file_path, 'r', encoding='utf-8') as f_source:\n",
    "\n",
    "        # Read and strip lines from both files\n",
    "        target_lines = [line.strip() for line in f_target]\n",
    "        source_lines = [line.strip() for line in f_source]\n",
    "\n",
    "        # Split source lines on '#'\n",
    "        source_splits = [src.split('#') for src in source_lines]\n",
    "\n",
    "        # For each line, remove the text that corresponds to\n",
    "        # [0] (before first '#') and [2] (after second '#'), keeping only [1].\n",
    "        for i, splits in enumerate(source_splits):\n",
    "            # Make sure there are indeed 3 parts after splitting\n",
    "            # (if your real data can have a different count, guard accordingly)\n",
    "            if len(splits) == 3:\n",
    "                before_text = splits[0]\n",
    "                middle_text = splits[1]  # we want to *keep* what's between the two '#'\n",
    "                after_text = splits[2]\n",
    "\n",
    "                # Remove 'before_text' and 'after_text' from the target line\n",
    "                # so that effectively only the portion corresponding to 'middle_text' remains.\n",
    "                target_lines[i] = target_lines[i].replace(before_text, '')\n",
    "                target_lines[i] = target_lines[i].replace(after_text, '')\n",
    "\n",
    "        return target_lines\n",
    "\n",
    "def main():\n",
    "    # Define explicit pairs of hypothesis and target files\n",
    "    # Format: (hypothesis_file_path, target_file_path)\n",
    "    file_pairs = [\n",
    "        (\"hypo_files/Qwen_Qwen2.5-7B_CoT.hypo\", \"D1test/semevaldata.target\", \"D1test/semevaldata.source\"),\n",
    "        (\"hypo_files/Qwen_Qwen2.5-7B_few_shot.hypo\", \"D1test/semevaldata.target\", \"D1test/semevaldata.source\"),\n",
    "        (\"hypo_files/Qwen_Qwen2.5-7B_zero_shot.hypo\", \"D1test/semevaldata.target\", \"D1test/semevaldata.source\")\n",
    "    ]\n",
    "    \n",
    "    # Output CSV file to store evaluation results\n",
    "    output_csv = 'evaluation_results.csv'\n",
    "    \n",
    "    # Initialize metrics\n",
    "    bleu = evaluate.load('bleu')\n",
    "    bertscore = evaluate.load('bertscore')\n",
    "    rouge = evaluate.load('rouge')  # Optional, if ROUGE is desired\n",
    "    \n",
    "    # Prepare CSV header\n",
    "    csv_header = ['Model', 'Source File', 'BLEU-1', 'BLEU-2', \n",
    "                  'ROUGE-1', 'ROUGE-2', 'ROUGE-L', \n",
    "                  'BERTScore Precision', 'BERTScore Recall', 'BERTScore F1']\n",
    "    \n",
    "    # Open CSV file for writing\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(csv_header)\n",
    "        \n",
    "        print(f\"Starting evaluation of {len(file_pairs)} file pairs.\\n\")\n",
    "        \n",
    "        # Iterate over each file pair with a progress bar\n",
    "        for hypo_path, target_path, source_path in tqdm(file_pairs, desc=\"Evaluating file pairs\"):\n",
    "            # Extract model identifier and source file name from the hypothesis file name\n",
    "            hypo_filename = os.path.basename(hypo_path)\n",
    "            \n",
    "            # Check if both files exist\n",
    "            if not os.path.exists(hypo_path):\n",
    "                print(f\"Hypothesis file not found: {hypo_path}. Skipping.\")\n",
    "                continue\n",
    "            if not os.path.exists(target_path):\n",
    "                print(f\"Target file not found: {target_path}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Load texts\n",
    "            generated_hypo_texts = load_texts(hypo_path, source_path)\n",
    "            with open(target_path, 'r', encoding='utf-8') as f_target:\n",
    "                # Read and strip lines from both files\n",
    "                target_texts = [line.strip() for line in f_target]\n",
    "                print(f\"Loaded {len(generated_hypo_texts)} hypothesis and {len(target_texts)} target texts.\")\n",
    "                #print 5 examples for each file\n",
    "                print(f\"Example hypothesis texts: {generated_hypo_texts[:5]}\")\n",
    "                print(f\"Example target texts: {target_texts[:5]}\")\n",
    "            \n",
    "            \n",
    "            # Validate that all datasets have the same number of samples\n",
    "            if len(target_texts) != len(generated_hypo_texts):\n",
    "                print(f\"Line count mismatch between hypothesis and target for {hypo_filename}. Skipping.\")\n",
    "                continue  # Skip if line counts do not match\n",
    "            \n",
    "            # Compute BLEU-1\n",
    "            bleu1 = bleu.compute(\n",
    "                predictions=generated_hypo_texts,\n",
    "                references=[[ref] for ref in target_texts],\n",
    "                max_order=1\n",
    "            )\n",
    "            \n",
    "            # Compute BLEU-2\n",
    "            bleu2 = bleu.compute(\n",
    "                predictions=generated_hypo_texts,\n",
    "                references=[[ref] for ref in target_texts],\n",
    "                max_order=2\n",
    "            )\n",
    "            \n",
    "            # Compute ROUGE\n",
    "            ro = rouge.compute(\n",
    "                predictions=generated_hypo_texts,\n",
    "                references=target_texts,\n",
    "                use_stemmer=True\n",
    "            )\n",
    "            \n",
    "            # Compute BERTScore\n",
    "            bs = bertscore.compute(\n",
    "                predictions=generated_hypo_texts,\n",
    "                references=target_texts,\n",
    "                lang='en',\n",
    "                model_type='bert-base-uncased',\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Calculate average BERTScore metrics\n",
    "            bert_precision = sum(bs['precision']) / len(bs['precision']) * 100\n",
    "            bert_recall = sum(bs['recall']) / len(bs['recall']) * 100\n",
    "            bert_f1 = sum(bs['f1']) / len(bs['f1']) * 100\n",
    "            \n",
    "            # Write results to CSV\n",
    "            writer.writerow([\n",
    "                hypo_filename,\n",
    "                f\"{bleu1['bleu'] * 100:.2f}\",\n",
    "                f\"{bleu2['bleu'] * 100:.2f}\",\n",
    "                f\"{ro['rouge1'] * 100:.2f}\",\n",
    "                f\"{ro['rouge2'] * 100:.2f}\",\n",
    "                f\"{ro['rougeL'] * 100:.2f}\",\n",
    "                f\"{bert_precision:.2f}\",\n",
    "                f\"{bert_recall:.2f}\",\n",
    "                f\"{bert_f1:.2f}\"\n",
    "            ])\n",
    "            \n",
    "            # Print summary for this pair\n",
    "            print(f\"Evaluated {hypo_filename}: BLEU-1={bleu1['bleu'] * 100:.2f}, BLEU-2={bleu2['bleu'] * 100:.2f}, ROUGE-1={ro['rouge1'] * 100:.2f}, ROUGE-2={ro['rouge2'] * 100:.2f}, ROUGE-L={ro['rougeL'] * 100:.2f}, BERTScore F1={bert_f1:.2f}\")\n",
    "        \n",
    "        print(f\"\\nEvaluation completed. Results saved to {output_csv}.\")\n",
    "\n",
    "# Execute the evaluation\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
